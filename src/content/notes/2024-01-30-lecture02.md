---
page: 'CMU 15721'
date: 2024-01-30
---

## _Lecture Note_ 02. Data Formats & Encoding I

OLAP workloads tends to do sequential scans on large segments of read-only data, while OLTP workloads mostly find individual tuples.

Sequential scan optimizations:

- data encoding / compression (this lecture)
- data parallelization / vectorization (next lecture)
- code specialization / compilation (later this semeter)
- prefetching, clustering / sorting, late materialization, materialized views / result caching... (intro class)

### Storage Models

1. NSM (**N**-ary **S**torage **M**odel)
   - tuple continuously
   - ideal for OLTP workloads (access individual entities / insert-heavy)
   - fixed page size
   - most OLTP DBMSs (PG, MySQL, Oracle)
1. DSM (**D**ecomposition **S**torage **M**odel)
   - attribute continuously
   - ideal for OLAP (query a subset of attributes)
   - **fixed-length** offsets over embedded tuple IDs (How to convert variable-length data into fixed-length? **Dictionary compression** over padding)
1. PAX (**P**artition **A**ttributes A**cross**)
   - hybrid, row groups + column chunks
   - faster processing + spatial locality

### Persistent Data Format

Design decisions from Apache Parquet / Apache ORC:

- **Meta-data** Self-contained over 'catalog + data'. Global meta-data included in each group: table schemas, row group offsets / length, tuple counts / zone maps, etc.
- **Format layout** PAX.
- **Type system** Physical type vs. logical type (e.g. integer vs. timestamp)
- **Encoding scheme** Dictionary compression.
- **Block compression** Computational overhead is over network / disk.
- **Filter** Zone maps and bloom filters.
- **Nested data**

Lessons learned:

- Dictionary encoding is effective for all data types.
- Simplistic encoding schemes are better on modern hardwares.
- Avoid general-purpose block compression since network / disk are no longer the bottleneck relative to CPU performance.
